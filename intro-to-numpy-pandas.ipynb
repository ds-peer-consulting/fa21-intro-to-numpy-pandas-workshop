{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"images/Screen Shot 2021-09-21 at 3.45.10 PM.png\" width=\"1200\" style=\"float:center\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Welcome to the Intro to Numpy + Pandas Workshop**\n",
    "By Jillian Criscuolo, Aashritha Srirambhatla, Nayan Chavan, Mein Lee\n",
    "\n",
    "In Collaboration with the Division of Data Science's [Data Peer Consulting](https://data.berkeley.edu/ds-peer-consulting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEFORE WE BEGIN PLEASE COMPLETE THIS SURVEY\n",
    "[Pre-Workshop Survey Link](https://docs.google.com/forms/d/e/1FAIpQLSeW_6oyWOlByhGUrVKTJvvQaQw4dHmvSXpJIF-dI5lxWzPO7g/viewform?usp=sf_link)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jillian Criscuolo \n",
    "![Vincent](images/jillian_criscuolo_photo_-_jillian_criscuolo.jpg)\n",
    "\n",
    "Quick Facts About Me:\n",
    "\n",
    "    üêª Senior at Cal\n",
    "    üéí Studying Data Science\n",
    "    üè¢ Interned as a Solutions Consultant Analyst @ Adobe\n",
    "    üìä Joined the Data Peer Consulting team in Fall 2020\n",
    "\n",
    "How to Reach Me:\n",
    "\n",
    "    üìÆ Email: jcriscuolo@berkeley.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aashritha Srirambhatla\n",
    "![Vincent](images/aashritha_srirambhatla_0.jpeg)\n",
    "\n",
    "Quick Facts About Me:\n",
    "\n",
    "    üêª Junior at Cal\n",
    "    üéí Studying Data Science\n",
    "    üè¢ Interned as an Analyst @ Amazon\n",
    "    üìä Joined the Data Peer Consulting team in Spring 2021\n",
    "\n",
    "How to Reach Me:\n",
    "\n",
    "    üìÆ Email: aashritha@berkeley.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nayan Chavan\n",
    "![Vincent](images/4e86ab73-918d-4234-b13a-8cd37c0ec35b-bcbcee29-223d-472e-b616-111bb85c30fe_-_nayan_chavan-1.jpg)\n",
    "\n",
    "Quick Facts About Me:\n",
    "\n",
    "    üêª Senior at Cal\n",
    "    üéí Studying Data Science with a minor in Computer Science\n",
    "    üè¢ Interned as a SWE @ Goldman Sachs\n",
    "    üìä Joined the Data Peer Consulting team in Fall 2020\n",
    "\n",
    "How to Reach Me:\n",
    "\n",
    "    üìÆ Email: nayanchavan@berkeley.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mein Lee\n",
    "![Vincent](images/c8782657-7ea5-4cd7-b83b-343e1201653f_-_mein_en_lee.jpeg)\n",
    "\n",
    "Quick Facts About Me:\n",
    "\n",
    "    üêª Senior at Cal\n",
    "    üéí Studying Data Science\n",
    "    üè¢ Interned as an AWS ASEAN @ Amazon\n",
    "    üìä Joined the Data Peer Consulting team in Spring 2021\n",
    "\n",
    "How to Reach Me:\n",
    "\n",
    "    üìÆ Email: meinlee@berkeley.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Workshop Goals\n",
    "\n",
    "The goal of this workshop is to cover the fundamentals of numpy and Pandas and give a working knowledge of these two major packages. By the end of the workshop, you should be able to fluently manipulate Numpy arrays, as well as be able to do basic (Excel/SQL style) table operations on data using Pandas. \n",
    "\n",
    "    - Understand the fundamental similarities and differences between Numpy arrays and Python lists as well as when to use one or the other. \n",
    "    - Apply the basic Pandas data structures as well as the basic table operations onto dataframes \n",
    "    - Demonstrate the basic workflow for intaking data and exploring it using Numpy and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"tof\"></a>\n",
    "## Table of Contents\n",
    "\n",
    "Use anchors to set these hyperlinks to jump to certain locations in the notebook. \n",
    "\n",
    "- [Numpy](#1)\n",
    "- [Pandas](#2)\n",
    "- [Reference Sheets](#rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a class=\"anchor\" id=\"1\"></a>\n",
    "## Numpy Fundamentals\n",
    "[Back to Table of Contents](#tof)\n",
    "\n",
    "NumPy stands for \"Numerical Python\". What this means is that Numpy is a package used for fast, efficient numerical calculations in Python. Numpy uses what we will call ***Numpy Arrays***, which are very similar to Python lists, but have a couple of key differences that we will take a look at.\n",
    "\n",
    "To use the Numpy package (or any other package), we must always import it into whatever text editor (program used for coding, e.g. Jupyter Notebook) that we are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard import statement for Numpy \n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the NumPy package with the shorthand `np`! We access various functions inside this package with `np.function(*arguments)`, where function() is the function you would like to use.\n",
    "\n",
    "[Jump to Key Difference 3](#kd3)  \n",
    "[Jump to Numpy Functions](#npfuncs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without further ado, let's talk about the differences between NumPy arrays and Python lists!  \n",
    "\n",
    "---\n",
    "\n",
    "**Key Difference 1:** They have different data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python list\n",
    "# The notation to create one is using square brackets. You can create an empty one like so:\n",
    "list1 = []\n",
    "type(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy array\n",
    "# Notice that by passing a Python list into the np.array() function as an argument, it turns it into a NumPy array!\n",
    "array1 = np.array([])\n",
    "type(array1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Difference 2:** Python lists can contain any kind of data type, and keeps them the way they are. However, NumPy objects can only contain data of the same type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['any', 123, 'kind', 456, 'of', 0.26973684210526316, 'data', True, 'type']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list2 = ['any', 123, 'kind', 456, 'of', 123/456, 'data', True, 'type']\n",
    "list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['any', '123', 'kind', '456', 'of', '0.26973684210526316', 'data',\n",
       "       'True', 'type'], dtype='<U19')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array2 = np.array(list2)\n",
    "array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('123', 123)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array2[1], list2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.str_, int)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(array2[1]), type(list2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does NumPy determine which data type to turn everything into then? \n",
    "\n",
    "Out of the primitive* data types, there's a \"data type hierarchy\" so to speak. NumPy will turn all the entries into the most complex data type that it finds in the array. The hierarchy is as follows, from least complex to most complex:\n",
    "- **Boolean < Integer < Float < String**\n",
    "\n",
    "\\**primitive data types: boolean - true/false, integer, float - decimal numbers, string - letters*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1. , 0. , 1. , 2. , 3. , 1.1, 2.2, 3.3]), array([1, 0, 1, 2, 3]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some more examples\n",
    "np.array([True, False, 1, 2, 3, 1.1, 2.2, 3.3]), np.array([True, False, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- True values turn into 1\n",
    "- False values turn into 0\n",
    "- Integers get a decimal point\n",
    "- Floats turn into strings, indicated by the quotation marks around them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Difference 3 [Very Important] :** Numerical operations with Python lists has different behavior than adding NumPy arrays.  <a class=\"anchor\" id=\"kd3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 1, 2, 3]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list3 = [1, 2, 3]\n",
    "list4 = [1, 2, 3]\n",
    "list3 + list4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-cf018c9e2a89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlist3\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlist4\u001b[0m \u001b[1;31m# error is expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'list'"
     ]
    }
   ],
   "source": [
    "list3 - list4 # error is expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-57efab2eec5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlist3\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlist4\u001b[0m \u001b[1;31m# error is expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'list'"
     ]
    }
   ],
   "source": [
    "list3 * list4 # error is expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list3 / list4 # error is expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: we are not reassigning this value to list3, so the result we see printed out under this cell is not permanent\n",
    "list3 + [4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we put strings inside the Python lists?\n",
    "string_list1 = ['test', '1', '2', '3']\n",
    "string_list2 = ['test', '4', '5', '6']\n",
    "string_list1 + string_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now with Numpy Arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array3 = np.array(list3) # Q: What is happening here? A: Think about replacing \"list3\" with the value assigned to it!\n",
    "array4 = np.array(list4)\n",
    "array3 + array4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 12, 13])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array3 + 10 # automatically performs element-wise arithmetic: [1+10, 2+10, 3+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 20, 30])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array3 * 10 # [1*10, 2*10, 3*10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array3 - array4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 9])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array3 * array4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array3 / array4 # notice it automatically converts things to floats when we divide!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  4, 27], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array3 ** array4 # ** denotes exponents, which also works for NumPy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types dtype('<U4') dtype('<U4') dtype('<U4')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-1c864bce445b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstring_array1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstring_array2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'4'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'6'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mstring_array1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstring_array2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types dtype('<U4') dtype('<U4') dtype('<U4')"
     ]
    }
   ],
   "source": [
    "# What if we put strings inside the NumPy arrays? [Error expected]\n",
    "string_array1 = np.array(['test', '1', '2', '3'])\n",
    "string_array2 = np.array(['test', '4', '5', '6'])\n",
    "string_array1 + string_array2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In short, there are some limitations to both. \n",
    "- Python lists can hold multiple data types at a time, while NumPy arrays can only hold one data type at a time\n",
    "- Adding Python lists *concatenates* them, while adding NumPy arrays performs element-wise addition\n",
    "- Other operations on Python lists don't work, but any numerical operation works element-wise with NumPy arrays\n",
    "\n",
    "---\n",
    "\n",
    "Now, let's learn some very common NumPy array functions besides `np.array()`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commonly Used NumPy Functions <a class=\"anchor\" id=\"npfuncs\"></a>\n",
    "Here are the corresponding NumPy documentations for reference:\n",
    "- [np.append](https://numpy.org/doc/stable/reference/generated/numpy.append.html)\n",
    "- [np.arange](https://numpy.org/doc/stable/reference/generated/numpy.arange.html)\n",
    "- [np.linspace](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html)\n",
    "\n",
    "Alternatively, when your typing line is hovering over a function, you can click `shift` + `tab` to open up the same documentation in Jupyter Notebook. Handy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Since addition doesn't allow us to *concatenate* two NumPy arrays, we have to have another way to do so.\n",
    "`np.append` does exactly that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-print the arrays for reference\n",
    "array5 = np.array([4,5,6])\n",
    "array4, array5, string_array1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.append\n",
    "np.append(array4, array5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data types still change accordingly after appending\n",
    "np.append(array4, string_array1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "`np.arange` creates a list of numbers based on the arguments you pass in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.arange(start value, stop value, step size); stop value is not included!\n",
    "# default start is 0, stop value is required (no default), default step size is 1 \n",
    "np.arange(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(2,6,2) # Before running this, try to predict what it will print out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "`np.linspace` creates a list of `n` values that are perfectly evenly spaced between `start value` and `stop value`, where `n = number of values`.\n",
    "\n",
    "This is very handy for when you need to create visualizations, and you want your tick marks or bins to be perfectly spaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.linspace(start value, stop value, number of values); the stop value IS included\n",
    "np.linspace(1,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(1,10,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"number of values\" has a default of 50\n",
    "np.linspace(0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "There are many functions that calculate various descriptive statistics as well. Note that you can pass in either a NumPy array or a Python list, as its argument.\n",
    "\n",
    "- np.min\n",
    "- np.max\n",
    "- np.sum\n",
    "- np.mean\n",
    "- np.median\n",
    "- np.std\n",
    "- np.percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233]\n",
    "np.min(numbers), np.max(numbers), np.sum(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(numbers), np.std(numbers), np.median(numbers), np.percentile(numbers, 50) # 50th percentile = median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Another handy aspect of Numpy arrays is that they can be treated as vectors, allowing linear algebra operations such as dot product. \n",
    "\n",
    "- np.dot\n",
    "- np.transpose\n",
    "\n",
    "... and many more! You can read about Numpy linear algebra operations [here](https://numpy.org/doc/stable/reference/routines.linalg.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Append array B1 to A1\n",
    "\n",
    "**Hint**: Think about the commonly used Numpy functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = np.array([1, 2, 3, 4, 5])\n",
    "B1 = np.array([6, 7, 8, 9, 10])\n",
    "\n",
    "### Your solution here\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Find the *maximum* of the *flattened* array of matrix C2\n",
    "\n",
    "Hint: Take a look at the [ndarray docs](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.flatten.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C2 = np.array([[1, 2, 3, 4, 5],\n",
    "              [6, 7, 8, 9, 10]])\n",
    "\n",
    "### Your solution here\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Find the *inner product* of matrices A3 and B3. \n",
    "\n",
    "**Hint**: Take a look at the [linalg docs](https://numpy.org/doc/stable/reference/routines.linalg.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "A3 = np.array([[1, 2, 3, 4, 5],\n",
    "              [6, 7, 8, 9, 10]])\n",
    "\n",
    "B3 = np.array([[11, 12, 13, 14, 15],\n",
    "             [16, 17, 18, 19, 20]])\n",
    "\n",
    "### Your solution here\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a class=\"anchor\" id=\"2\"></a>\n",
    "## Pandas Fundamentals\n",
    "[Back to Table of Contents](#tof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll just go ahead and continue into Pandas!\n",
    "\n",
    "Pandas stands for \"**Pan**el **Da**ta\" (I know, not as good as NumPy). This is just referring to the tables, or **dataframes**, that Pandas works with. Dataframes are the most common and intuitive way for both humans and computers to organize data.\n",
    "\n",
    "Being able to manipulate those dataframes is crucial for data scientists to be able to clean up their data in a way that is usable for analysis. \n",
    "\n",
    "This is where Pandas comes in.\n",
    "\n",
    "We will talk about two main methods of cleaning our data to get ready for visualization:\n",
    "1. [Filtering](#filtering)\n",
    "2. [Grouping](#grouping)\n",
    "\n",
    "But before learning the more techinical stuff, here's a quick introduction to Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the conventional Pandas import statement\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 main functions for Pandas in the [data science life cycle](https://towardsdatascience.com/data-science-life-cycle-101-for-dummies-like-me-e66b47ad8d8f).\n",
    "\n",
    "1. Reading in data\n",
    "2. Summarizing the data\n",
    "3. Cleaning the data  \n",
    "    a. Stratify by grouping and filtering for certain subsets of the dataframe  \n",
    "    b. Fill in or remove missing data  \n",
    "    c. Combine various dataframes into a single dataframe  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this workshop, we'll focus on the knowledge of Pandas that is helpful for creating great visualizations.\n",
    "\n",
    "First, let's introduce the DataFrame and Series data types.  \n",
    "\n",
    "A DataFrame is like a 2D table of information. Each row is called a **record or observation** because rows typically represent some real life event or object. And each column is called a **feature** because it's an aspect of the real life event or object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pandas reads in data and creates a DataFrame object of them\n",
    "lib_traffic = pd.read_csv('data/HourlyTraffic-2019-12-11.csv')\n",
    "\n",
    "# dataframe.head() returns the first 5 rows and all the columns of the dataframe\n",
    "lib_traffic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of this dataset, each record represents an event -- the traffic of a specific location at a specific time. \n",
    "\n",
    "\n",
    "Each column represents a piece of information regarding each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a sanity check for the data type of lib_traffic\n",
    "type(lib_traffic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To grab certain parts of the dataframe, we can use slicing notation, similar to how we slice into Python lists or NumPy arrays. For a dataframe inside the variable `df`, we can slice like this:\n",
    "```\n",
    "df['column_name']\n",
    "```\n",
    "and it will give us a **Series**. <a class=\"anchor\" id=\"series\"></a>\n",
    "\n",
    "A **Series** is a special data type that represents the column of a dataframe. A **Series** works very similar to a NumPy because it is *literally* a NumPy array with some extra functions built into it. More information about **Series** is always a Google search away, if you are interested in learning more about those extra functions.\n",
    "\n",
    "[Back to Exercise 1](#ex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabs the Entries column as a Series from the dataframe\n",
    "lib_traffic['Entries'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a sanity check for the data type of the Entries column\n",
    "type(lib_traffic['Entries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series behaving like a NumPy array\n",
    "lib_traffic['Entries'][10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lib_traffic['Entries'][10:20] * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering with Pandas <a class=\"anchor\" id=\"filtering\"></a>\n",
    "By filtering, we can remove data that we are uninterested in. Here are two main ideas we can use filtering for:\n",
    "- keep data that fall within a range of values to narrow our scope for visualization\n",
    "- remove faulty data or outliers that skew the perception of our visualizations\n",
    "\n",
    "As we introduced in our last workshop, the most common format to filter data is as follows:\n",
    "```\n",
    "table_name[table_name[column] == value] # Only keep rows with this value in the selected column\n",
    "table_name[table_name[column] != value] # Only keep rows WITHOUT this value in the selected column\n",
    "table_name[table_name[column] > value] # Only keep rows with greater values in the selected column\n",
    "```\n",
    "\n",
    "[Jump to Exercise 3](#ex3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, given our library traffic dataset, let's say that we want the data that only pertains to Doe Library. First, let's look at the different facilities to see how to spell \"Doe Library\" exactly. This is important, because without the *exact* same spelling and capitaliation, Python will not recognize what you want, and will error or return the incorrect data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one of the special functions that Series have is the `unique` function that gives all the unique values of a Series \n",
    "lib_traffic['Facility'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that this returns an empty dataframe. Why? Because looking at the strings above, the `Doe` should be capitalized.\n",
    "lib_traffic[lib_traffic['Facility'] == \"Doe Library\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# again, but with proper capitalization\n",
    "doe = lib_traffic[lib_traffic['Facility'] == \"DOE Library\"]\n",
    "doe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we narrowed our data down to Doe Library, we can see that there are two different entrances to Doe, and that there is an entry for each hour of 12/11/19. Then, there should be 24 * 2 different entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check for table size; `.shape` gives us the shape of the dataframe in the format (rows, column)\n",
    "doe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a couple of other examples of things we can do with filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_traffic[lib_traffic['Entries'] > 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_traffic[lib_traffic['Region'] == \"UC Berkeley\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lib_traffic[lib_traffic['Region'] != \"UC Berkeley\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be wondering, what does the `NaN` mean? `NaN` is a common thing you will see with **missing/faulty data**. We won't talk about what to do with this, or how to take care of it, but just know that it is something to think about when working with a dataset.\n",
    "\n",
    "---\n",
    "\n",
    "You can also filter by multiple conditions by putting each condition in parentheses, and combining them with an ampersand (&). You can separate this into multiple lines, or just put it all together in the same line. For the sake of readibility, we put it in separate lines in this format example:\n",
    "```\n",
    "condition1 = table_name[column1] == value1\n",
    "condition1 = table_name[column2] >= value2\n",
    "table_name[(condition1) & (condition2)] # Only keep rows with both conditions satisfied\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition1 = lib_traffic['Exits'] > 200\n",
    "condition2 = lib_traffic['Entries'] > 200\n",
    "lib_traffic[(condition1) & (condition2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# both formats work, and generate the same result!\n",
    "lib_traffic[(lib_traffic['Exits'] > 200) & (lib_traffic['Entries'] > 200)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now, as a final example, let's say we are trying to find the record with the largest number of entries at Doe. We can do this in two steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, find the largest number in the `Entries` column\n",
    "max_entries = np.max(doe['Entries'])\n",
    "\n",
    "# then, find the row(s) that match `max_entries` in the Doe dataframe\n",
    "doe[doe['Entries'] == max_entries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this single-record dataframe, we see that the time where there was the most entries into Doe Library on 12/11/19 was at 3pm.\n",
    "\n",
    "In sum, using filtering, we can grab certain aspects of data that we want, and see more clearly specific points of interest. Later on, we will see how this can be useful for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping with Pandas <a class=\"anchor\" id=\"grouping\"></a>\n",
    "By grouping, we can stratify our dataset by the unique values of a specific column in our dataset. Then, we can create visualizations based on the different stratas, and compare how they appear similar or different.\n",
    "\n",
    "[Jump to Exercise 3](#ex3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use the `groupby` function with Pandas, we will get a dataframe where:\n",
    "- the column you specify to group by will become the index\n",
    "- there will be 1 row for each unique value in the column\n",
    "- every other column is aggregated by the function you choose\n",
    "\n",
    "---\n",
    "\n",
    "The syntax for groupby is as follows:\n",
    "```\n",
    "df.groupby(column).aggregation_function()\n",
    "```\n",
    "If we simply call `groupby` on our dataframe, it doesn't quite do anything yet. We get back a **groupby object**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_traffic.groupby('Facility')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can then aggregate by a specific function. There are a couple of common defaults built into groupby that we'll use today.\n",
    "- sum: sums all the values of each column in the group\n",
    "- mean: calculated the mean of all the values of each column in the group\n",
    "- min:  same as above but minimum\n",
    "- max: same as above but maximum\n",
    "- count: counts the number of rows in the group\n",
    "\n",
    "For example, we can group by `Facility` in order to get the sum number of people that enter and exit each library, regardless of which entrance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lib_traffic.groupby('Facility').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice 2 things:\n",
    "1. There is 1 row for each unique facility, as expected\n",
    "2. Many of the columns disappeared. Why?\n",
    "\n",
    "We're left with only 2 columns because those are the only columns where our aggregation function, summing, makes sense. It doesn't make sense to take the sum of a bunch of strings, or of a bunch of different dates, so Pandas automatically gets rid of them. Neat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lib_traffic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some more examples; we add .head() to shorten the dataframe that is printed out\n",
    "lib_traffic.groupby('Facility').mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lib_traffic.groupby('Facility').min().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_traffic.groupby('Facility').max().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lib_traffic.groupby('Facility').count().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last note:\n",
    "\n",
    "You can groupby multiple columns! This creates a multi-index table, where each unique set of column values corresponds to a row in the table. The syntax is as follows:\n",
    "```\n",
    "df.groupby([column1, column2]).aggregation_function()\n",
    "```\n",
    "\n",
    "Let's group by `Date-Time` and `Facility` to see the total number of people entering __each library__ at __each hour__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_lib_traffic = lib_traffic.groupby([\"Date-Time\", \"Facility\"]).sum()\n",
    "total_lib_traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the first index is all the unique date-times, and the second index is a repeated list of all the unique libraries that have a record for that date-time. So the number of rows is equal to (# unique date-times) * (# unique facilities). \n",
    "\n",
    "We can interpret the first row as \"On 12/11/19, in the hour of 9:00am-10:00am, 6 people entered AHC Library.\"\n",
    "\n",
    "#### Now we'll get into some Numpy and Pandas exercises! <a class=\"anchor\" id=\"ex1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ex1\"></a>\n",
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the minimum, maximum, average, and total number of people that entered any library.\n",
    "\n",
    "Hint: We can get a NumPy array version of any column by using the Series syntax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your solution here\n",
    "\n",
    "... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"2\"></a>\n",
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the net sum number of people that entered each library at each hour.\n",
    "\n",
    "*Hint*: net sum entered = Entries - Exits\n",
    "\n",
    "*Hint2*: The sum of the resulting array should be 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your solution here\n",
    "\n",
    "... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ex3\"></a>\n",
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe from lib_traffic that has the total number of people that enter and exit any library at each time of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your solution here\n",
    "\n",
    "... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ex4\"></a>\n",
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the same dataframe as above, but instead of any library, look only at the Engineering Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your solution here\n",
    "\n",
    "... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ex5\"></a>\n",
    "## Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe that has the maximum number of people that enter and exit each entrance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your solution here\n",
    "\n",
    "... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thanks for Coming! PLEASE COMPLETE THIS POST-WORKSHOP SURVEY!  \n",
    "[Post-Workshop Survey Link Here](https://forms.gle/gfuYbKTFEscnkrMY8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"rs\"></a>\n",
    "### Reference Sheets!\n",
    "[Back to Table of Contents](#tof)\n",
    "\n",
    "Links updated as of 1/1/11.\n",
    "\n",
    "- [NumPy Cheat Sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf)  \n",
    "- [Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)  \n",
    "- [Matplotlib Cheat Sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Python_Matplotlib_Cheat_Sheet.pdf)  \n",
    "- [Seaborn Cheat Sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Python_Seaborn_Cheat_Sheet.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Resources\n",
    "1. Data Peer Consultants - That's us! We help undergrads and graduate students with projects, research, and more! Come to our drop-in hours.  \n",
    "https://data.berkeley.edu/ds-peer-consulting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Towards Data Science - Website full of good blogs and helpful introductions to data science stuff.  \n",
    "https://towardsdatascience.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Stack Overflow // Google - A great data scientist is adept at using StackOverflow and Google to find the answers to their bugs. More likely than not, someone out there has ran into the exact same problem as you, so might as well use their solutions as a resource!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
